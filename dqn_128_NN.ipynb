{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arresejo/misc/blob/main/dqn_128_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PfkNIPuWkZA7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from keras.models import Sequential, load_model, clone_model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from collections import deque\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAABNpcOkdAC",
        "outputId": "42066b93-e738-4b3f-a693-8ea8bee60502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 39.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 448 kB 8.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "\n",
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iC_c4xpakj6V"
      },
      "outputs": [],
      "source": [
        "env_name = \"LunarLander-v2\"\n",
        "env = gym.make(env_name).unwrapped\n",
        "\n",
        "#env.spec.max_episode_steps = 3000\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCs9YKcfUl1V",
        "outputId": "312e07e2-1d62-4c09-b011-2d11b4a7f358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 15 07:39:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU5OWVi-UsX8",
        "outputId": "685ce0c9-1c50-42e1-b2cb-a3b1f4fb888a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0DxbfBwpkkfk"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    def __init__(self, env, batch_size, gamma, alpha, epsilon, epsilon_decay, epsilon_min, update_frequency, memory_size):\n",
        "        self.env = env\n",
        "        if not self.env.continuous:  # discrete\n",
        "            self.num_actions = 4  # line 170 in source code: https://github.com/openai/gym/blob/master/gym/envs/box2d/lunar_lander.py\n",
        "        else:\n",
        "            return f\"you still did not work on coninuous...\"\n",
        "        self.memory_size = memory_size\n",
        "        memory_space = 8 + 1 + 1 + 8 + 1  # states, action, reward, next_state, terminal   # TDL (soft-code it from the env)\n",
        "        self.memory_counter = 0\n",
        "        #self.memory = np.zeros((memory_space, self.memory_size))\n",
        "        self.memory = deque(maxlen=memory_size)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        # self.num_episodes = num_episodes  # in the train method\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.update_frequency = update_frequency\n",
        "\n",
        "    def agent_model(self, layer_list, input_dims, lr, loss, optimizer):  # fcn\n",
        "        model = Sequential()\n",
        "        for l in layer_list:\n",
        "            model.add(l)\n",
        "        model.compile(optimizer=optimizer(learning_rate=lr), loss=loss)\n",
        "        return model\n",
        "\n",
        "    def store_in_memory(self, sarst_list):  # sarst_list := (state,action,next_state,reward,terminal)\n",
        "        # store transition (S, A, R, S', terminal) in replay memory D\n",
        "        self.memory[:, self.memory_counter % self.memory_size] = np.concatenate(\n",
        "            tuple(np.array(x, dtype=float, ndmin=1) for x in sarst_list))\n",
        "        self.memory_counter += 1\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.random() > self.epsilon:\n",
        "            action = np.argmax(self.model_q1.predict(state.reshape((1, 8))))  # epsilon-greedy\n",
        "        else:\n",
        "            action = np.random.randint(self.num_actions)\n",
        "        return action\n",
        "\n",
        "    def get_rand_sample(self):\n",
        "        batch_indexes = np.random.choice(len(np.array(self.memory)), self.batch_size)\n",
        "\n",
        "        states, actions, next_states, rewards, terminals = ([] for _ in range(5))\n",
        "\n",
        "        for index in batch_indexes:\n",
        "            states.append(self.memory[index][0])\n",
        "            actions.append(self.memory[index][1])\n",
        "            next_states.append(self.memory[index][2])\n",
        "            rewards.append(self.memory[index][3])\n",
        "            terminals.append(self.memory[index][4])\n",
        "\n",
        "        return np.array(states).squeeze(), \\\n",
        "               np.array(actions).squeeze(), \\\n",
        "               np.array(next_states), \\\n",
        "               np.array(rewards), \\\n",
        "               np.array(terminals)\n",
        "\n",
        "    def train(self, num_episodes, layer_list, input_dims=8, loss='mse',\n",
        "              optimizer=Adam):  # TDL: default of input_dims as num of states\n",
        "        self.model_q1 = self.agent_model(layer_list, input_dims, self.alpha, loss, optimizer)\n",
        "        #self.model_q2 = clone_model(self.model_q1)\n",
        "        #self.model_q2.set_weights(self.model_q1.get_weights())\n",
        "        reward_steps_hist = []  # tupple per episode:  (reward, num_steps)\n",
        "        scores  = []\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            total_reward = 0\n",
        "            steps = 0\n",
        "            terminal = False\n",
        "            state = self.env.reset()  # seed=seed\n",
        "\n",
        "            score = 0\n",
        "\n",
        "            if episode != 0 and episode % 20 == 0:\n",
        "              self.model_q1.save(\"/content/saved_models/model_\"+str(episode)+\"_episodes.h5\")\n",
        "\n",
        "            #while not terminal:\n",
        "            for _ in range(3000):\n",
        "                action = self.choose_action(state)\n",
        "                next_state, reward, terminal, _ = self.env.step(action)\n",
        "\n",
        "                self.memory.append((state, action, next_state, reward, terminal))\n",
        "\n",
        "                total_reward += reward\n",
        "\n",
        "                if len(self.memory) >= self.batch_size:\n",
        "\n",
        "                    states, actions, next_states, rewards, terminals = self.get_rand_sample()\n",
        "\n",
        "                    #q_next_state = self.model_q1.predict_on_batch(next_states)\n",
        "                    #q_target = self.model_q1.predict_on_batch(states)\n",
        "                    q_next_state = self.model_q1.predict(next_states)\n",
        "                    q_target = self.model_q1.predict(states)\n",
        "\n",
        "                    #q_target[np.arange(self.batch_size), actions] = rewards + (terminals == 0) * self.gamma * np.amax(q_next_state, axis=1)\n",
        "                    q_target[np.arange(self.batch_size), actions] = rewards + self.gamma * np.amax(q_next_state, axis=1) *  (1 - terminals)\n",
        "\n",
        "                    self.model_q1.fit(states, q_target, verbose=0)\n",
        "\n",
        "                    self.epsilon = np.max(((self.epsilon * self.epsilon_decay), self.epsilon_min))\n",
        "\n",
        "                state = next_state\n",
        "                score += reward\n",
        "                steps += 1\n",
        "\n",
        "                if terminal:\n",
        "                  scores.append(score)\n",
        "                  print(\"Episode = {}, Score = {}, Avg_Score = {}\".format(episode, score, np.mean(scores[-100:])))\n",
        "                  print((episode, total_reward, steps, self.epsilon))\n",
        "                  break\n",
        "\n",
        "            print(f\"End of episode {episode}\")\n",
        "\n",
        "            #print((episode, total_reward, steps, self.epsilon))\n",
        "\n",
        "            reward_steps_hist.append((total_reward, steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JytCmXm-koiT",
        "outputId": "39768e41-39f2-4bd3-f275-2f9781698fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode = 0, Score = -111.62410467234731, Avg_Score = -111.62410467234731\n",
            "(0, -111.62410467234731, 110, 0.8283023736574049)\n",
            "End of episode 0\n",
            "Episode = 1, Score = -159.0263411855378, Avg_Score = -135.32522292894257\n",
            "(1, -159.0263411855378, 91, 0.5751600363283949)\n",
            "End of episode 1\n",
            "Episode = 2, Score = -230.92644392482126, Avg_Score = -167.19229659423547\n",
            "(2, -230.92644392482126, 95, 0.3930301369795873)\n",
            "End of episode 2\n",
            "Episode = 3, Score = 18.131013564500563, Avg_Score = -120.86146905455146\n",
            "(3, 18.131013564500563, 87, 0.27732453635319726)\n",
            "End of episode 3\n",
            "Episode = 4, Score = -487.86209045050396, Avg_Score = -194.26159333374196\n",
            "(4, -487.86209045050396, 309, 0.08037553348057996)\n",
            "End of episode 4\n",
            "Episode = 5, Score = -696.069777538496, Avg_Score = -277.896290701201\n",
            "(5, -696.069777538496, 75, 0.05950784872013358)\n",
            "End of episode 5\n",
            "Episode = 6, Score = -322.0690952579678, Avg_Score = -284.2066913521677\n",
            "(6, -322.0690952579678, 53, 0.04811928734513095)\n",
            "End of episode 6\n",
            "Episode = 7, Score = -294.5031170288611, Avg_Score = -285.49374456175434\n",
            "(7, -294.5031170288611, 102, 0.031972139997142573)\n",
            "End of episode 7\n",
            "Episode = 8, Score = -3.302738763186994, Avg_Score = -254.1391883619135\n",
            "(8, -3.302738763186994, 165, 0.016502986555687233)\n",
            "End of episode 8\n",
            "Episode = 9, Score = -381.18738509965397, Avg_Score = -266.8440080356876\n",
            "(9, -381.18738509965397, 1710, 0.01)\n",
            "End of episode 9\n",
            "Episode = 10, Score = 158.33605374999314, Avg_Score = -228.19127514608024\n",
            "(10, 158.33605374999314, 706, 0.01)\n",
            "End of episode 10\n",
            "Episode = 11, Score = -60.29560817159289, Avg_Score = -214.19996956487296\n",
            "(11, -60.29560817159289, 358, 0.01)\n",
            "End of episode 11\n",
            "Episode = 12, Score = -31.440946671298732, Avg_Score = -200.14158318844417\n",
            "(12, -31.440946671298732, 296, 0.01)\n",
            "End of episode 12\n",
            "Episode = 13, Score = -160.53550501698638, Avg_Score = -197.31257760476862\n",
            "(13, -160.53550501698638, 567, 0.01)\n",
            "End of episode 13\n",
            "Episode = 14, Score = -124.56248528296564, Avg_Score = -192.46257144998174\n",
            "(14, -124.56248528296564, 217, 0.01)\n",
            "End of episode 14\n",
            "Episode = 15, Score = -161.35461431171652, Avg_Score = -190.51832412884016\n",
            "(15, -161.35461431171652, 256, 0.01)\n",
            "End of episode 15\n",
            "Episode = 16, Score = -215.89077565114962, Avg_Score = -192.01082127721133\n",
            "(16, -215.89077565114962, 208, 0.01)\n",
            "End of episode 16\n",
            "Episode = 17, Score = -231.9799922249855, Avg_Score = -194.23133077430987\n",
            "(17, -231.9799922249855, 184, 0.01)\n",
            "End of episode 17\n",
            "Episode = 18, Score = -162.68638242183135, Avg_Score = -192.57107033470575\n",
            "(18, -162.68638242183135, 214, 0.01)\n",
            "End of episode 18\n",
            "Episode = 19, Score = -67.0540068365373, Avg_Score = -186.29521715979732\n",
            "(19, -67.0540068365373, 642, 0.01)\n",
            "End of episode 19\n",
            "Episode = 20, Score = 8.601774208756538, Avg_Score = -177.01440804700903\n",
            "(20, 8.601774208756538, 314, 0.01)\n",
            "End of episode 20\n",
            "Episode = 21, Score = -168.04827484569512, Avg_Score = -176.60685653785842\n",
            "(21, -168.04827484569512, 767, 0.01)\n",
            "End of episode 21\n",
            "Episode = 22, Score = -1.789605685013683, Avg_Score = -169.0061065007782\n",
            "(22, -1.789605685013683, 178, 0.01)\n",
            "End of episode 22\n",
            "Episode = 23, Score = -44.903568380913775, Avg_Score = -163.83516741245055\n",
            "(23, -44.903568380913775, 307, 0.01)\n",
            "End of episode 23\n",
            "Episode = 24, Score = -91.2329175942762, Avg_Score = -160.93107741972358\n",
            "(24, -91.2329175942762, 125, 0.01)\n",
            "End of episode 24\n",
            "Episode = 25, Score = -29.864719802329006, Avg_Score = -155.8900636652084\n",
            "(25, -29.864719802329006, 112, 0.01)\n",
            "End of episode 25\n",
            "Episode = 26, Score = -21.927499128068476, Avg_Score = -150.92848720086988\n",
            "(26, -21.927499128068476, 315, 0.01)\n",
            "End of episode 26\n",
            "Episode = 27, Score = 1.9737093421457388, Avg_Score = -145.46769446719074\n",
            "(27, 1.9737093421457388, 212, 0.01)\n",
            "End of episode 27\n",
            "Episode = 28, Score = 177.58477960379483, Avg_Score = -134.32795398198436\n",
            "(28, 177.58477960379483, 835, 0.01)\n",
            "End of episode 28\n",
            "Episode = 29, Score = -78.01587599703122, Avg_Score = -132.45088471581926\n",
            "(29, -78.01587599703122, 212, 0.01)\n",
            "End of episode 29\n",
            "End of episode 30\n",
            "Episode = 31, Score = -231.1349094021864, Avg_Score = -135.63424035086337\n",
            "(31, -231.1349094021864, 2607, 0.01)\n",
            "End of episode 31\n",
            "Episode = 32, Score = 191.60350519338897, Avg_Score = -125.40806080260543\n",
            "(32, 191.60350519338897, 487, 0.01)\n",
            "End of episode 32\n",
            "Episode = 33, Score = -210.608123196789, Avg_Score = -127.98988087515646\n",
            "(33, -210.608123196789, 1033, 0.01)\n",
            "End of episode 33\n",
            "Episode = 34, Score = -87.14899802050735, Avg_Score = -126.788678438255\n",
            "(34, -87.14899802050735, 133, 0.01)\n",
            "End of episode 34\n",
            "Episode = 35, Score = -146.99242240309945, Avg_Score = -127.36592826582198\n",
            "(35, -146.99242240309945, 353, 0.01)\n",
            "End of episode 35\n",
            "Episode = 36, Score = -112.35578621185621, Avg_Score = -126.94897987543403\n",
            "(36, -112.35578621185621, 836, 0.01)\n",
            "End of episode 36\n",
            "End of episode 37\n",
            "Episode = 38, Score = 93.22663595678664, Avg_Score = -120.99828755564428\n",
            "(38, 93.22663595678664, 735, 0.01)\n",
            "End of episode 38\n",
            "Episode = 39, Score = -109.30925807983527, Avg_Score = -120.69068151680722\n",
            "(39, -109.30925807983527, 114, 0.01)\n",
            "End of episode 39\n",
            "Episode = 40, Score = -71.91021535327567, Avg_Score = -119.43990033312693\n",
            "(40, -71.91021535327567, 382, 0.01)\n",
            "End of episode 40\n",
            "Episode = 41, Score = -194.5494080524889, Avg_Score = -121.31763802611098\n",
            "(41, -194.5494080524889, 239, 0.01)\n",
            "End of episode 41\n",
            "Episode = 42, Score = 226.95520020368636, Avg_Score = -112.82317855709155\n",
            "(42, 226.95520020368636, 727, 0.01)\n",
            "End of episode 42\n",
            "Episode = 43, Score = -73.68745971284723, Avg_Score = -111.89137572746668\n",
            "(43, -73.68745971284723, 140, 0.01)\n",
            "End of episode 43\n",
            "Episode = 44, Score = 64.40043431192856, Avg_Score = -107.79156619166679\n",
            "(44, 64.40043431192856, 671, 0.01)\n",
            "End of episode 44\n",
            "Episode = 45, Score = -104.73470265505082, Avg_Score = -107.72209202038006\n",
            "(45, -104.73470265505082, 440, 0.01)\n",
            "End of episode 45\n",
            "Episode = 46, Score = -82.00906619689252, Avg_Score = -107.15069144652477\n",
            "(46, -82.00906619689252, 410, 0.01)\n",
            "End of episode 46\n",
            "Episode = 47, Score = -213.74327403228273, Avg_Score = -109.46792150273691\n",
            "(47, -213.74327403228273, 843, 0.01)\n",
            "End of episode 47\n",
            "Episode = 48, Score = -29.02863232491883, Avg_Score = -107.756447264911\n",
            "(48, -29.02863232491883, 230, 0.01)\n",
            "End of episode 48\n",
            "Episode = 49, Score = 143.6260315871702, Avg_Score = -102.51931228882597\n",
            "(49, 143.6260315871702, 643, 0.01)\n",
            "End of episode 49\n",
            "Episode = 50, Score = 174.31892644033923, Avg_Score = -96.86955231476138\n",
            "(50, 174.31892644033923, 421, 0.01)\n",
            "End of episode 50\n",
            "Episode = 51, Score = 148.40266708017464, Avg_Score = -91.96410792686265\n",
            "(51, 148.40266708017464, 526, 0.01)\n",
            "End of episode 51\n",
            "Episode = 52, Score = 11.575707490439342, Avg_Score = -89.93391546769986\n",
            "(52, 11.575707490439342, 1527, 0.01)\n",
            "End of episode 52\n",
            "Episode = 53, Score = 30.634191984861275, Avg_Score = -87.61529801668908\n",
            "(53, 30.634191984861275, 348, 0.01)\n",
            "End of episode 53\n",
            "Episode = 54, Score = -281.2063974384056, Avg_Score = -91.267960269929\n",
            "(54, -281.2063974384056, 255, 0.01)\n",
            "End of episode 54\n",
            "Episode = 55, Score = 72.80151651630364, Avg_Score = -88.22963662573953\n",
            "(55, 72.80151651630364, 1714, 0.01)\n",
            "End of episode 55\n",
            "Episode = 56, Score = 149.27819675120128, Avg_Score = -83.91131238252242\n",
            "(56, 149.27819675120128, 648, 0.01)\n",
            "End of episode 56\n",
            "Episode = 57, Score = 7.636144103129439, Avg_Score = -82.27653637385006\n",
            "(57, 7.636144103129439, 257, 0.01)\n",
            "End of episode 57\n",
            "Episode = 58, Score = 169.62243430415117, Avg_Score = -77.85725618651671\n",
            "(58, 169.62243430415117, 518, 0.01)\n",
            "End of episode 58\n",
            "Episode = 59, Score = 159.88685957476628, Avg_Score = -73.7582197078739\n",
            "(59, 159.88685957476628, 416, 0.01)\n",
            "End of episode 59\n",
            "Episode = 60, Score = 47.78253258355798, Avg_Score = -71.69820695717166\n",
            "(60, 47.78253258355798, 1447, 0.01)\n",
            "End of episode 60\n",
            "Episode = 61, Score = -53.178934546786536, Avg_Score = -71.38955241699858\n",
            "(61, -53.178934546786536, 230, 0.01)\n",
            "End of episode 61\n",
            "Episode = 62, Score = 212.79734540985316, Avg_Score = -66.7307508132797\n",
            "(62, 212.79734540985316, 729, 0.01)\n",
            "End of episode 62\n",
            "Episode = 63, Score = 169.84427487405242, Avg_Score = -62.91502459251628\n",
            "(63, 169.84427487405242, 332, 0.01)\n",
            "End of episode 63\n",
            "Episode = 64, Score = 138.00327582538267, Avg_Score = -59.72584522080359\n",
            "(64, 138.00327582538267, 534, 0.01)\n",
            "End of episode 64\n",
            "Episode = 65, Score = 145.69970777063267, Avg_Score = -56.5160709553124\n",
            "(65, 145.69970777063267, 504, 0.01)\n",
            "End of episode 65\n",
            "Episode = 66, Score = 201.98054128967902, Avg_Score = -52.539199997697146\n",
            "(66, 201.98054128967902, 353, 0.01)\n",
            "End of episode 66\n",
            "Episode = 67, Score = -111.899571821471, Avg_Score = -53.43859957078463\n",
            "(67, -111.899571821471, 125, 0.01)\n",
            "End of episode 67\n",
            "End of episode 68\n",
            "Episode = 69, Score = 118.59758711802831, Avg_Score = -50.87089529184712\n",
            "(69, 118.59758711802831, 874, 0.01)\n",
            "End of episode 69\n",
            "Episode = 70, Score = 200.51301269702384, Avg_Score = -47.174073115540196\n",
            "(70, 200.51301269702384, 303, 0.01)\n",
            "End of episode 70\n",
            "Episode = 71, Score = 229.1296864882785, Avg_Score = -43.169670802441374\n",
            "(71, 229.1296864882785, 423, 0.01)\n",
            "End of episode 71\n",
            "Episode = 72, Score = 216.06028539665616, Avg_Score = -39.466385713882836\n",
            "(72, 216.06028539665616, 507, 0.01)\n",
            "End of episode 72\n",
            "Episode = 73, Score = -159.7976113717331, Avg_Score = -41.16119170906383\n",
            "(73, -159.7976113717331, 143, 0.01)\n",
            "End of episode 73\n",
            "Episode = 74, Score = -45.83673690311251, Avg_Score = -41.22612983675895\n",
            "(74, -45.83673690311251, 424, 0.01)\n",
            "End of episode 74\n",
            "Episode = 75, Score = 197.05131462690412, Avg_Score = -37.96205525506494\n",
            "(75, 197.05131462690412, 444, 0.01)\n",
            "End of episode 75\n",
            "Episode = 76, Score = 182.5465645287598, Avg_Score = -34.982209041770005\n",
            "(76, 182.5465645287598, 440, 0.01)\n",
            "End of episode 76\n",
            "Episode = 77, Score = 260.4433906553671, Avg_Score = -31.043201045808175\n",
            "(77, 260.4433906553671, 430, 0.01)\n",
            "End of episode 77\n",
            "Episode = 78, Score = -83.36186494733084, Avg_Score = -31.731604518196633\n",
            "(78, -83.36186494733084, 958, 0.01)\n",
            "End of episode 78\n",
            "Episode = 79, Score = 6.8862338749241445, Avg_Score = -31.230074149454808\n",
            "(79, 6.8862338749241445, 211, 0.01)\n",
            "End of episode 79\n",
            "Episode = 80, Score = 198.66073420580605, Avg_Score = -28.28275609361813\n",
            "(80, 198.66073420580605, 676, 0.01)\n",
            "End of episode 80\n",
            "Episode = 81, Score = 245.02756612793033, Avg_Score = -24.823131761699795\n",
            "(81, 245.02756612793033, 497, 0.01)\n",
            "End of episode 81\n",
            "Episode = 82, Score = 234.810401511076, Avg_Score = -21.577712595790096\n",
            "(82, 234.810401511076, 505, 0.01)\n",
            "End of episode 82\n",
            "Episode = 83, Score = -50.019829372750294, Avg_Score = -21.9288498399501\n",
            "(83, -50.019829372750294, 103, 0.01)\n",
            "End of episode 83\n",
            "Episode = 84, Score = 155.8790945537832, Avg_Score = -19.760460274172864\n",
            "(84, 155.8790945537832, 491, 0.01)\n",
            "End of episode 84\n",
            "Episode = 85, Score = -66.19391925171527, Avg_Score = -20.31989953896253\n",
            "(85, -66.19391925171527, 155, 0.01)\n",
            "End of episode 85\n",
            "Episode = 86, Score = -15.949210181168766, Avg_Score = -20.26786752279832\n",
            "(86, -15.949210181168766, 297, 0.01)\n",
            "End of episode 86\n",
            "Episode = 87, Score = 245.0581948217129, Avg_Score = -17.146384436392307\n",
            "(87, 245.0581948217129, 327, 0.01)\n",
            "End of episode 87\n",
            "Episode = 88, Score = 260.64348401414054, Avg_Score = -13.916269686967505\n",
            "(88, 260.64348401414054, 383, 0.01)\n",
            "End of episode 88\n",
            "Episode = 89, Score = -89.83796978623238, Avg_Score = -14.788932906499285\n",
            "(89, -89.83796978623238, 353, 0.01)\n",
            "End of episode 89\n",
            "Episode = 90, Score = -63.33772919012827, Avg_Score = -15.340623773358708\n",
            "(90, -63.33772919012827, 227, 0.01)\n",
            "End of episode 90\n",
            "Episode = 91, Score = -63.16453830938377, Avg_Score = -15.877971127696066\n",
            "(91, -63.16453830938377, 182, 0.01)\n",
            "End of episode 91\n",
            "Episode = 92, Score = 258.42585697309335, Avg_Score = -12.830150815465075\n",
            "(92, 258.42585697309335, 559, 0.01)\n",
            "End of episode 92\n",
            "Episode = 93, Score = -46.55665949617653, Avg_Score = -13.200771789978386\n",
            "(93, -46.55665949617653, 493, 0.01)\n",
            "End of episode 93\n",
            "Episode = 94, Score = -14.693735991281727, Avg_Score = -13.216999661731684\n",
            "(94, -14.693735991281727, 299, 0.01)\n",
            "End of episode 94\n",
            "Episode = 95, Score = 217.35432406632646, Avg_Score = -10.737738116268694\n",
            "(95, 217.35432406632646, 358, 0.01)\n",
            "End of episode 95\n",
            "Episode = 96, Score = 222.18021274633713, Avg_Score = -8.259887575177142\n",
            "(96, 222.18021274633713, 351, 0.01)\n",
            "End of episode 96\n",
            "Episode = 97, Score = 212.65224538030392, Avg_Score = -5.934496701961552\n",
            "(97, 212.65224538030392, 467, 0.01)\n",
            "End of episode 97\n",
            "Episode = 98, Score = 232.71341340632117, Avg_Score = -3.4485809716669387\n",
            "(98, 232.71341340632117, 531, 0.01)\n",
            "End of episode 98\n",
            "Episode = 99, Score = 284.0260345990058, Avg_Score = -0.4849251410414464\n",
            "(99, 284.0260345990058, 381, 0.01)\n",
            "End of episode 99\n",
            "Episode = 100, Score = -451.2677379988347, Avg_Score = -5.084749762039337\n",
            "(100, -451.2677379988347, 564, 0.01)\n",
            "End of episode 100\n",
            "Episode = 101, Score = 252.98774208157636, Avg_Score = -2.477956915134128\n",
            "(101, 252.98774208157636, 439, 0.01)\n",
            "End of episode 101\n",
            "Episode = 102, Score = 268.69827873815495, Avg_Score = 0.23380544139876291\n",
            "(102, 268.69827873815495, 281, 0.01)\n",
            "End of episode 102\n",
            "Episode = 103, Score = 260.1561397252453, Avg_Score = 3.9516078853746905\n",
            "(103, 260.1561397252453, 535, 0.01)\n",
            "End of episode 103\n",
            "Episode = 104, Score = -45.84135679622372, Avg_Score = 5.083457729267831\n",
            "(104, -45.84135679622372, 198, 0.01)\n",
            "End of episode 104\n",
            "Episode = 105, Score = 131.90959060264277, Avg_Score = 8.711818074542471\n",
            "(105, 131.90959060264277, 935, 0.01)\n",
            "End of episode 105\n",
            "Episode = 106, Score = 216.9690657597072, Avg_Score = 10.700198596494538\n",
            "(106, 216.9690657597072, 316, 0.01)\n",
            "End of episode 106\n",
            "Episode = 107, Score = 188.76235944200639, Avg_Score = 17.466443095419642\n",
            "(107, 188.76235944200639, 756, 0.01)\n",
            "End of episode 107\n",
            "Episode = 108, Score = 17.485078155730477, Avg_Score = 24.601991652361914\n",
            "(108, 17.485078155730477, 190, 0.01)\n",
            "End of episode 108\n",
            "Episode = 109, Score = 41.20426270346567, Avg_Score = 28.234725231976245\n",
            "(109, 41.20426270346567, 166, 0.01)\n",
            "End of episode 109\n",
            "Episode = 110, Score = -52.3154070459389, Avg_Score = 30.656602331805466\n",
            "(110, -52.3154070459389, 202, 0.01)\n",
            "End of episode 110\n",
            "Episode = 111, Score = 177.89777759045108, Avg_Score = 32.46860749534184\n",
            "(111, 177.89777759045108, 657, 0.01)\n",
            "End of episode 111\n",
            "Episode = 112, Score = 238.63903516410446, Avg_Score = 38.666871697979424\n",
            "(112, 238.63903516410446, 461, 0.01)\n",
            "End of episode 112\n",
            "Episode = 113, Score = 239.5396100677214, Avg_Score = 39.4789072611567\n",
            "(113, 239.5396100677214, 286, 0.01)\n",
            "End of episode 113\n",
            "Episode = 114, Score = 187.58406932137507, Avg_Score = 41.95770403608639\n",
            "(114, 187.58406932137507, 536, 0.01)\n",
            "End of episode 114\n",
            "Episode = 115, Score = 208.12025478395833, Avg_Score = 44.35331605063896\n",
            "(115, 208.12025478395833, 467, 0.01)\n",
            "End of episode 115\n",
            "Episode = 116, Score = 147.92565490485202, Avg_Score = 47.43792764985736\n",
            "(116, 147.92565490485202, 766, 0.01)\n",
            "End of episode 116\n",
            "Episode = 117, Score = 273.2082313600878, Avg_Score = 51.415634816287884\n",
            "(117, 273.2082313600878, 235, 0.01)\n",
            "End of episode 117\n",
            "Episode = 118, Score = 0.212030537701267, Avg_Score = 53.03130126478206\n",
            "(118, 0.212030537701267, 231, 0.01)\n",
            "End of episode 118\n",
            "Episode = 119, Score = 265.84193355945956, Avg_Score = 57.84862835688815\n",
            "(119, 265.84193355945956, 367, 0.01)\n",
            "End of episode 119\n",
            "Episode = 120, Score = 279.2016593393462, Avg_Score = 62.96044487253148\n",
            "(120, 279.2016593393462, 277, 0.01)\n",
            "End of episode 120\n",
            "Episode = 121, Score = 29.26884022705903, Avg_Score = 64.87999709902037\n",
            "(121, 29.26884022705903, 240, 0.01)\n",
            "End of episode 121\n",
            "Episode = 122, Score = 227.0528846934089, Avg_Score = 67.82106601431983\n",
            "(122, 227.0528846934089, 525, 0.01)\n",
            "End of episode 122\n",
            "Episode = 123, Score = 243.7133118087554, Avg_Score = 70.17218139031982\n",
            "(123, 243.7133118087554, 562, 0.01)\n",
            "End of episode 123\n",
            "Episode = 124, Score = 231.50416316573757, Avg_Score = 74.16770577043414\n",
            "(124, 231.50416316573757, 384, 0.01)\n",
            "End of episode 124\n",
            "Episode = 125, Score = 231.07327778918724, Avg_Score = 76.49633460517616\n",
            "(125, 231.07327778918724, 443, 0.01)\n",
            "End of episode 125\n",
            "Episode = 126, Score = 178.87160264494847, Avg_Score = 78.73408631543477\n",
            "(126, 178.87160264494847, 403, 0.01)\n",
            "End of episode 126\n",
            "Episode = 127, Score = 218.12457778491097, Avg_Score = 81.82766126922665\n",
            "(127, 218.12457778491097, 448, 0.01)\n",
            "End of episode 127\n",
            "Episode = 128, Score = 185.0209188514276, Avg_Score = 83.9765176557642\n",
            "(128, 185.0209188514276, 430, 0.01)\n",
            "End of episode 128\n",
            "Episode = 129, Score = 226.07945956187982, Avg_Score = 86.4565872426637\n",
            "(129, 226.07945956187982, 435, 0.01)\n",
            "End of episode 129\n",
            "Episode = 130, Score = 272.6910123950163, Avg_Score = 89.16376027319238\n",
            "(130, 272.6910123950163, 424, 0.01)\n",
            "End of episode 130\n",
            "Episode = 131, Score = 265.93661076912474, Avg_Score = 90.0472785848457\n",
            "(131, 265.93661076912474, 377, 0.01)\n",
            "End of episode 131\n",
            "Episode = 132, Score = 185.92848668547373, Avg_Score = 92.68672221167076\n",
            "(132, 185.92848668547373, 616, 0.01)\n",
            "End of episode 132\n",
            "Episode = 133, Score = 192.15373341826194, Avg_Score = 96.91960863987524\n",
            "(133, 192.15373341826194, 764, 0.01)\n",
            "End of episode 133\n",
            "Episode = 134, Score = -26.294283063190875, Avg_Score = 94.74063075730943\n",
            "(134, -26.294283063190875, 422, 0.01)\n",
            "End of episode 134\n",
            "Episode = 135, Score = 114.94797474654354, Avg_Score = 97.99619173674277\n",
            "(135, 114.94797474654354, 763, 0.01)\n",
            "End of episode 135\n",
            "Episode = 136, Score = 279.43704220998654, Avg_Score = 101.6620521390477\n",
            "(136, 279.43704220998654, 378, 0.01)\n",
            "End of episode 136\n",
            "Episode = 137, Score = 241.6632985131465, Avg_Score = 105.54860934821018\n",
            "(137, 241.6632985131465, 681, 0.01)\n",
            "End of episode 137\n",
            "Episode = 138, Score = 145.3068106604071, Avg_Score = 108.12523531693282\n",
            "(138, 145.3068106604071, 936, 0.01)\n",
            "End of episode 138\n",
            "Episode = 139, Score = 179.70544943073529, Avg_Score = 108.99002345167231\n",
            "(139, 179.70544943073529, 602, 0.01)\n",
            "End of episode 139\n",
            "Episode = 140, Score = 213.1413467628044, Avg_Score = 112.2145295000987\n",
            "(140, 213.1413467628044, 289, 0.01)\n",
            "End of episode 140\n",
            "Episode = 141, Score = 57.42412803671989, Avg_Score = 113.50787293399864\n",
            "(141, 57.42412803671989, 963, 0.01)\n",
            "End of episode 141\n",
            "Episode = 142, Score = 298.35601751575956, Avg_Score = 118.43692718968114\n",
            "(142, 298.35601751575956, 339, 0.01)\n",
            "End of episode 142\n",
            "Episode = 143, Score = 217.76020934802443, Avg_Score = 118.3449772811245\n",
            "(143, 217.76020934802443, 312, 0.01)\n",
            "End of episode 143\n",
            "Episode = 144, Score = 274.915414075508, Avg_Score = 121.83100601900806\n",
            "(144, 274.915414075508, 323, 0.01)\n",
            "End of episode 144\n",
            "Episode = 145, Score = 256.8967136417961, Avg_Score = 123.7559688123067\n",
            "(145, 256.8967136417961, 353, 0.01)\n",
            "End of episode 145\n",
            "Episode = 146, Score = 263.2786683614078, Avg_Score = 127.43610252247132\n",
            "(146, 263.2786683614078, 358, 0.01)\n",
            "End of episode 146\n",
            "Episode = 147, Score = 211.5431197253738, Avg_Score = 130.37162438169398\n",
            "(147, 211.5431197253738, 447, 0.01)\n",
            "End of episode 147\n",
            "Episode = 148, Score = 120.37694389449754, Avg_Score = 133.71282656096182\n",
            "(148, 120.37694389449754, 811, 0.01)\n",
            "End of episode 148\n",
            "Episode = 149, Score = 176.01167336158954, Avg_Score = 135.76322961782688\n",
            "(149, 176.01167336158954, 1407, 0.01)\n",
            "End of episode 149\n",
            "Episode = 150, Score = 188.0196505729862, Avg_Score = 136.20716580768504\n",
            "(150, 188.0196505729862, 1470, 0.01)\n",
            "End of episode 150\n",
            "Episode = 151, Score = 268.6771791045884, Avg_Score = 137.15074833432752\n",
            "(151, 268.6771791045884, 430, 0.01)\n",
            "End of episode 151\n",
            "Episode = 152, Score = 200.373322824036, Avg_Score = 137.67045489176613\n",
            "(152, 200.373322824036, 450, 0.01)\n",
            "End of episode 152\n",
            "Episode = 153, Score = 238.95192249885756, Avg_Score = 139.94421704185032\n",
            "(153, 238.95192249885756, 553, 0.01)\n",
            "End of episode 153\n",
            "Episode = 154, Score = 286.2379783269459, Avg_Score = 142.50025490527116\n",
            "(154, 286.2379783269459, 269, 0.01)\n",
            "End of episode 154\n",
            "Episode = 155, Score = 205.17715502878357, Avg_Score = 147.36409042994308\n",
            "(155, 205.17715502878357, 392, 0.01)\n",
            "End of episode 155\n",
            "Episode = 156, Score = 265.48396170267915, Avg_Score = 149.29091488180683\n",
            "(156, 265.48396170267915, 449, 0.01)\n",
            "End of episode 156\n",
            "Episode = 157, Score = 275.24187726066316, Avg_Score = 150.55055168690143\n",
            "(157, 275.24187726066316, 367, 0.01)\n",
            "End of episode 157\n",
            "Episode = 158, Score = -19.00734632527943, Avg_Score = 150.28411678261736\n",
            "(158, -19.00734632527943, 116, 0.01)\n",
            "End of episode 158\n",
            "Episode = 159, Score = 207.780093480199, Avg_Score = 150.66569337437784\n",
            "(159, 207.780093480199, 559, 0.01)\n",
            "End of episode 159\n",
            "Episode = 160, Score = 141.69477773484363, Avg_Score = 150.48377255597862\n",
            "(160, 141.69477773484363, 824, 0.01)\n",
            "End of episode 160\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "gamma = .99\n",
        "alpha = .001\n",
        "\n",
        "epsilon = 1\n",
        "epsilon_decay = .996\n",
        "epsilon_min = .01\n",
        "\n",
        "update_frequency = 10  # in steps\n",
        "memory_size = 1000000\n",
        "num_episodes = 400\n",
        "\n",
        "layers_list = [Dense(128, input_shape=(8,), activation='relu'), Dense(128, activation='relu'), Dense(4, activation='linear')]  # TDL: soft-code inut_shape and num_actions (as part of the class)\n",
        "\n",
        "agent = Agent(env, batch_size, gamma, alpha, epsilon, epsilon_decay, epsilon_min, update_frequency, memory_size)\n",
        "\n",
        "agent.train(num_episodes, layers_list, input_dims=8, loss='mse', optimizer=Adam)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/u49l3N/8Kt6ccoxmFUeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}